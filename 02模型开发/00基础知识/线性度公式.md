针对集群的扩展能力（scalability），在论文 [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/pdf/2104.04473) 中的提到：
```
Pipeline model parallelism should be used primarily to support the
training of large models that do not fit on a single worker, and data
parallelism should be used to scale up training.
```
重点在后半句的说明：**DP 是用来进行扩展性训练的**。理想情况下，当集群的规模上去了，给入相当规模的数据在集群上进行训练时单卡上的吞吐与基线规模的单卡的吞吐量应该维持在比例系数1. 但在实际中，考虑机间通信等因素的影响，系数将不再维持1，计算公式如下：

假设存在一个基线规模的集群，记为 $C_{1}$，给定一组 TP PP 配置，那么能得到一个对应的 DP 配置 $D_{1}$，同时在该集群下单次迭代的训练数据为 $B_{1}$（给定序列长度 $s$，通过扩充 batch $b_{1}$ 来增加数据），此时迭代时长为 $t_{1}$，那么能得到吞吐为：

$$
P_{1} = \frac{B_{1}}{C_{1}×t_{1}} = \frac{s×b_{1}}{C_{1}×{t_{1}}}
$$

此时，开始扩充集群规模到 $C_{2}$（假设 $C_{2}=C_{1}×N$）, TP PP 配置保持切分策略，那么此时的 DP 域的大小就应该为

$$
DP = \frac{C_{2}}{TP × PP} = \frac{C_{1}×N}{TP × PP} = D_{1}×N
$$

同样地，我们也给入相当规模的数据量进去

$$
B_{2}=N×B_{1}=s×b_{2}=N×s×b_{1}
$$

此时的单步迭代时长为 $t_{2}$ 那么在 $C_{2}$ 这个集群下，能打到的吞吐就应该是

$$
P_{2}=\frac{B_{2}}{C_{2}×t_{2}}=\frac{N×s×b_{1}}{C_{1}×N×t_{2}}=\frac{s×b_{1}}{C_{1}×t_{2}}
$$

从而，线性度就可以表示为

$$
linearity=\frac{P_2}{P_1}=\frac{\frac{s×b_{1}}{C_{1}×t_{2}}}{\frac{s×b_{1}}{C_{1}×{t_{1}}}}=\frac{t_1}{t_2}
$$
