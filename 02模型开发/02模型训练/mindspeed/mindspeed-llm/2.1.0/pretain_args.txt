/root/miniconda3/envs/py310/lib/python3.10/tempfile.py:869: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpd0znh0uz'>
  _warnings.warn(warn_message, ResourceWarning)
usage: pretrain_gpt.py [-h] [--num-layers NUM_LAYERS]
                       [--encoder-num-layers ENCODER_NUM_LAYERS]
                       [--decoder-num-layers DECODER_NUM_LAYERS]
                       [--hidden-size HIDDEN_SIZE]
                       [--ffn-hidden-size FFN_HIDDEN_SIZE]
                       [--num-attention-heads NUM_ATTENTION_HEADS]
                       [--kv-channels KV_CHANNELS] [--group-query-attention]
                       [--num-query-groups NUM_QUERY_GROUPS]
                       [--max-position-embeddings MAX_POSITION_EMBEDDINGS]
                       [--position-embedding-type {learned_absolute,rope,none,alibi,alibi}]
                       [--use-rotary-position-embeddings]
                       [--rotary-base ROTARY_BASE]
                       [--rotary-percent ROTARY_PERCENT]
                       [--rotary-interleaved]
                       [--rotary-seq-len-interpolation-factor ROTARY_SEQ_LEN_INTERPOLATION_FACTOR]
                       [--no-position-embedding]
                       [--make-vocab-size-divisible-by MAKE_VOCAB_SIZE_DIVISIBLE_BY]
                       [--normalization {LayerNorm,RMSNorm}]
                       [--norm-epsilon NORM_EPSILON] [--apply-layernorm-1p]
                       [--apply-residual-connection-post-layernorm]
                       [--openai-gelu] [--squared-relu] [--swiglu]
                       [--onnx-safe ONNX_SAFE] [--bert-no-binary-head]
                       [--untie-embeddings-and-output-weights]
                       [--attention-dropout ATTENTION_DROPOUT]
                       [--hidden-dropout HIDDEN_DROPOUT]
                       [--weight-decay WEIGHT_DECAY]
                       [--start-weight-decay START_WEIGHT_DECAY]
                       [--end-weight-decay END_WEIGHT_DECAY]
                       [--weight-decay-incr-style {constant,linear,cosine}]
                       [--clip-grad CLIP_GRAD] [--adam-beta1 ADAM_BETA1]
                       [--adam-beta2 ADAM_BETA2] [--adam-eps ADAM_EPS]
                       [--sgd-momentum SGD_MOMENTUM]
                       [--micro-batch-size MICRO_BATCH_SIZE]
                       [--batch-size BATCH_SIZE]
                       [--global-batch-size GLOBAL_BATCH_SIZE]
                       [--rampup-batch-size [RAMPUP_BATCH_SIZE ...]]
                       [--recompute-activations]
                       [--recompute-granularity {full,selective}]
                       [--no-check-for-nan-in-loss-and-grad]
                       [--distribute-saved-activations]
                       [--recompute-method {uniform,block}]
                       [--recompute-num-layers RECOMPUTE_NUM_LAYERS]
                       [--no-clone-scatter-output-in-embedding] [--profile]
                       [--profile-step-start PROFILE_STEP_START]
                       [--profile-step-end PROFILE_STEP_END]
                       [--tp-comm-overlap]
                       [--tp-comm-overlap-cfg TP_COMM_OVERLAP_CFG]
                       [--disable-tp-comm-overlap-ag]
                       [--disable-tp-comm-overlap-rs]
                       [--tp-comm-overlap-rs-dgrad]
                       [--disable-tp-comm-bulk-dgrad]
                       [--disable-tp-comm-bulk-wgrad]
                       [--use-cpu-initialization]
                       [--empty-unused-memory-level {0,1,2}]
                       [--deterministic-mode]
                       [--check-weight-hash-across-dp-replicas-interval CHECK_WEIGHT_HASH_ACROSS_DP_REPLICAS_INTERVAL]
                       [--calculate-per-token-loss] [--checkpoint-activations]
                       [--train-iters TRAIN_ITERS]
                       [--train-samples TRAIN_SAMPLES]
                       [--log-interval LOG_INTERVAL]
                       [--exit-interval EXIT_INTERVAL]
                       [--exit-duration-in-mins EXIT_DURATION_IN_MINS]
                       [--exit-signal-handler]
                       [--tensorboard-dir TENSORBOARD_DIR]
                       [--no-masked-softmax-fusion] [--no-bias-gelu-fusion]
                       [--no-bias-swiglu-fusion] [--no-bias-dropout-fusion]
                       [--no-rope-fusion] [--cross-entropy-loss-fusion]
                       [--use-flash-attn] [--disable-bias-linear]
                       [--optimizer {adam,sgd}]
                       [--dataloader-type {single,cyclic,external}]
                       [--no-async-tensor-model-parallel-allreduce]
                       [--no-persist-layer-norm] [--sequence-parallel]
                       [--no-gradient-accumulation-fusion]
                       [--use-legacy-models] [--manual-gc]
                       [--manual-gc-interval MANUAL_GC_INTERVAL]
                       [--no-manual-gc-eval] [--disable-tp-comm-split-ag]
                       [--disable-tp-comm-split-rs] [--seed SEED]
                       [--data-parallel-random-init]
                       [--init-method-std INIT_METHOD_STD]
                       [--init-method-xavier-uniform] [--lr LR]
                       [--lr-decay-style {constant,linear,cosine,inverse-square-root,WSD}]
                       [--lr-wsd-decay-style {exponential,linear,cosine}]
                       [--lr-decay-iters LR_DECAY_ITERS]
                       [--lr-decay-samples LR_DECAY_SAMPLES]
                       [--lr-wsd-decay-samples LR_WSD_DECAY_SAMPLES]
                       [--lr-wsd-decay-iters LR_WSD_DECAY_ITERS]
                       [--lr-warmup-fraction LR_WARMUP_FRACTION]
                       [--lr-warmup-iters LR_WARMUP_ITERS]
                       [--lr-warmup-samples LR_WARMUP_SAMPLES]
                       [--lr-warmup-init LR_WARMUP_INIT] [--warmup WARMUP]
                       [--min-lr MIN_LR] [--override-opt_param-scheduler]
                       [--use-checkpoint-opt_param-scheduler]
                       [--decoupled-lr DECOUPLED_LR]
                       [--decoupled-min-lr DECOUPLED_MIN_LR] [--save SAVE]
                       [--save-interval SAVE_INTERVAL] [--no-save-optim]
                       [--no-save-rng] [--load LOAD] [--no-load-optim]
                       [--no-load-rng] [--finetune]
                       [--pretrained-checkpoint PRETRAINED_CHECKPOINT]
                       [--ckpt-step CKPT_STEP] [--no-initialization]
                       [--use-checkpoint-args] [--exit-on-missing-checkpoint]
                       [--use-dist-ckpt] [--auto-detect-ckpt-format]
                       [--dist-ckpt-format {zarr,torch_dist}]
                       [--ckpt-fully-parallel-save]
                       [--no-ckpt-fully-parallel-save] [--async-save]
                       [--ckpt-fully-parallel-load]
                       [--ckpt-assume-constant-structure]
                       [--dist-ckpt-strictness {assume_ok_unexpected,log_unexpected,log_all,raise_unexpected,raise_all,return_unexpected,return_all,ignore_all}]
                       [--fp16] [--bf16] [--loss-scale LOSS_SCALE]
                       [--initial-loss-scale INITIAL_LOSS_SCALE]
                       [--min-loss-scale MIN_LOSS_SCALE]
                       [--loss-scale-window LOSS_SCALE_WINDOW]
                       [--hysteresis HYSTERESIS] [--fp32-residual-connection]
                       [--apply-query-key-layer-scaling]
                       [--attention-softmax-in-fp32]
                       [--accumulate-allreduce-grads-in-fp32]
                       [--fp16-lm-cross-entropy]
                       [--tensor-model-parallel-size TENSOR_MODEL_PARALLEL_SIZE]
                       [--pipeline-model-parallel-size PIPELINE_MODEL_PARALLEL_SIZE]
                       [--pipeline-model-parallel-split-rank PIPELINE_MODEL_PARALLEL_SPLIT_RANK]
                       [--model-parallel-size MODEL_PARALLEL_SIZE]
                       [--num-layers-per-virtual-pipeline-stage NUM_LAYERS_PER_VIRTUAL_PIPELINE_STAGE]
                       [--no-overlap-p2p-communication]
                       [--distributed-backend {nccl,gloo}]
                       [--overlap-grad-reduce]
                       [--defer-embedding-wgrad-compute]
                       [--wgrad-deferral-limit WGRAD_DEFERRAL_LIMIT]
                       [--no-delay-grad-reduce]
                       [--ddp-bucket-size DDP_BUCKET_SIZE]
                       [--ddp-average-in-collective] [--overlap-param-gather]
                       [--delay-param-gather]
                       [--no-scatter-gather-tensors-in-pipeline]
                       [--use-ring-exchange-p2p] [--local_rank LOCAL_RANK]
                       [--lazy-mpu-init LAZY_MPU_INIT]
                       [--standalone-embedding-stage]
                       [--use-distributed-optimizer]
                       [--context-parallel-size CONTEXT_PARALLEL_SIZE]
                       [--nccl-communicator-config-path NCCL_COMMUNICATOR_CONFIG_PATH]
                       [--use-tp-pp-dp-mapping] [--eval-iters EVAL_ITERS]
                       [--eval-interval EVAL_INTERVAL] [--test-mode]
                       [--skip-train] [--data-path [DATA_PATH ...]]
                       [--split SPLIT]
                       [--train-data-path [TRAIN_DATA_PATH ...]]
                       [--valid-data-path [VALID_DATA_PATH ...]]
                       [--test-data-path [TEST_DATA_PATH ...]]
                       [--data-cache-path DATA_CACHE_PATH]
                       [--no-mmap-bin-files] [--mock-data]
                       [--vocab-size VOCAB_SIZE] [--vocab-file VOCAB_FILE]
                       [--merge-file MERGE_FILE]
                       [--vocab-extra-ids VOCAB_EXTRA_IDS]
                       [--seq-length SEQ_LENGTH]
                       [--encoder-seq-length ENCODER_SEQ_LENGTH]
                       [--decoder-seq-length DECODER_SEQ_LENGTH]
                       [--retriever-seq-length RETRIEVER_SEQ_LENGTH]
                       [--sample-rate SAMPLE_RATE] [--mask-prob MASK_PROB]
                       [--short-seq-prob SHORT_SEQ_PROB]
                       [--num-workers NUM_WORKERS]
                       [--tokenizer-model TOKENIZER_MODEL]
                       [--tiktoken-pattern TIKTOKEN_PATTERN]
                       [--tiktoken-num-special-tokens TIKTOKEN_NUM_SPECIAL_TOKENS]
                       [--tiktoken-special-tokens TIKTOKEN_SPECIAL_TOKENS [TIKTOKEN_SPECIAL_TOKENS ...]]
                       [--reset-position-ids] [--eod-mask-loss]
                       [--no-create-attention-mask-in-dataloader]
                       [--num-dataset-builder-threads NUM_DATASET_BUILDER_THREADS]
                       [--s3-cache-path S3_CACHE_PATH] [--adlr-autoresume]
                       [--adlr-autoresume-interval ADLR_AUTORESUME_INTERVAL]
                       [--ict-head-size ICT_HEAD_SIZE]
                       [--biencoder-projection-dim BIENCODER_PROJECTION_DIM]
                       [--biencoder-shared-query-context-model]
                       [--ict-load ICT_LOAD] [--bert-load BERT_LOAD]
                       [--titles-data-path TITLES_DATA_PATH]
                       [--query-in-block-prob QUERY_IN_BLOCK_PROB]
                       [--use-one-sent-docs]
                       [--evidence-data-path EVIDENCE_DATA_PATH]
                       [--retriever-report-topk-accuracies RETRIEVER_REPORT_TOPK_ACCURACIES [RETRIEVER_REPORT_TOPK_ACCURACIES ...]]
                       [--retriever-score-scaling]
                       [--block-data-path BLOCK_DATA_PATH]
                       [--embedding-path EMBEDDING_PATH]
                       [--indexer-batch-size INDEXER_BATCH_SIZE]
                       [--indexer-log-interval INDEXER_LOG_INTERVAL]
                       [--num-classes NUM_CLASSES] [--img-h IMG_H]
                       [--img-w IMG_W] [--num-channels NUM_CHANNELS]
                       [--patch-dim PATCH_DIM]
                       [--classes-fraction CLASSES_FRACTION]
                       [--data-per-class-fraction DATA_PER_CLASS_FRACTION]
                       [--no-data-sharding] [--head-lr-mult HEAD_LR_MULT]
                       [--vision-pretraining]
                       [--vision-pretraining-type {classify,inpaint,dino}]
                       [--vision-backbone-type {vit,mit,swin}]
                       [--swin-backbone-type {tiny,base,h3}]
                       [--mask-type {random,row}] [--mask-factor MASK_FACTOR]
                       [--iter-per-epoch ITER_PER_EPOCH]
                       [--dino-local-img-size DINO_LOCAL_IMG_SIZE]
                       [--dino-local-crops-number DINO_LOCAL_CROPS_NUMBER]
                       [--dino-head-hidden-size DINO_HEAD_HIDDEN_SIZE]
                       [--dino-bottleneck-size DINO_BOTTLENECK_SIZE]
                       [--dino-freeze-last-layer DINO_FREEZE_LAST_LAYER]
                       [--dino-norm-last-layer]
                       [--dino-warmup-teacher-temp DINO_WARMUP_TEACHER_TEMP]
                       [--dino-teacher-temp DINO_TEACHER_TEMP]
                       [--dino-warmup-teacher-temp-epochs DINO_WARMUP_TEACHER_TEMP_EPOCHS]
                       [--qk-layernorm]
                       [--expert-model-parallel-size EXPERT_MODEL_PARALLEL_SIZE]
                       [--num-experts NUM_EXPERTS]
                       [--moe-router-topk MOE_ROUTER_TOPK]
                       [--moe-router-pre-softmax] [--moe-grouped-gemm]
                       [--moe-aux-loss-coeff MOE_AUX_LOSS_COEFF]
                       [--moe-input-jitter-eps MOE_INPUT_JITTER_EPS]
                       [--moe-per-layer-logging]
                       [--moe-pad-expert-input-to-capacity]
                       [--moe-token-drop-policy {probs,position}]
                       [--moe-layer-recompute] [--moe-extended-tp]
                       [--log-params-norm] [--log-num-zeros-in-grad]
                       [--log-throughput] [--log-progress]
                       [--timing-log-level {0,1,2}]
                       [--no-barrier-with-level-1-timing]
                       [--timing-log-option {max,minmax,all}]
                       [--tensorboard-log-interval TENSORBOARD_LOG_INTERVAL]
                       [--tensorboard-queue-size TENSORBOARD_QUEUE_SIZE]
                       [--log-timers-to-tensorboard]
                       [--log-batch-size-to-tensorboard]
                       [--no-log-learnig-rate-to-tensorboard]
                       [--no-log-loss-scale-to-tensorboard]
                       [--log-validation-ppl-to-tensorboard]
                       [--log-memory-to-tensorboard]
                       [--log-world-size-to-tensorboard]
                       [--wandb-project WANDB_PROJECT]
                       [--wandb-exp-name WANDB_EXP_NAME]
                       [--wandb-save-dir WANDB_SAVE_DIR]
                       [--logging-level LOGGING_LEVEL] [--log-straggler]
                       [--disable-straggler-on-startup]
                       [--straggler-ctrlr-port STRAGGLER_CTRLR_PORT]
                       [--straggler-minmax-count STRAGGLER_MINMAX_COUNT]
                       [--inference-batch-times-seqlen-threshold INFERENCE_BATCH_TIMES_SEQLEN_THRESHOLD]
                       [--max-tokens-to-oom MAX_TOKENS_TO_OOM]
                       [--output-bert-embeddings]
                       [--bert-embedder-type {megatron,huggingface}]
                       [--fp8-format {e4m3,hybrid}] [--fp8-margin FP8_MARGIN]
                       [--fp8-interval FP8_INTERVAL]
                       [--fp8-amax-history-len FP8_AMAX_HISTORY_LEN]
                       [--fp8-amax-compute-algo {most_recent,max}]
                       [--no-fp8-wgrad]
                       [--retro-project-dir RETRO_PROJECT_DIR]
                       [--retro-add-retriever]
                       [--retro-cyclic-train-iters RETRO_CYCLIC_TRAIN_ITERS]
                       [--retro-encoder-layers RETRO_ENCODER_LAYERS]
                       [--retro-encoder-hidden-dropout RETRO_ENCODER_HIDDEN_DROPOUT]
                       [--retro-encoder-attention-dropout RETRO_ENCODER_ATTENTION_DROPOUT]
                       [--retro-num-neighbors RETRO_NUM_NEIGHBORS]
                       [--retro-num-retrieved-chunks RETRO_NUM_RETRIEVED_CHUNKS]
                       [--retro-attention-gate RETRO_ATTENTION_GATE]
                       [--retro-no-verify-neighbor-count] [--spec [SPEC ...]]
                       [--hybrid-attention-ratio HYBRID_ATTENTION_RATIO]
                       [--hybrid-mlp-ratio HYBRID_MLP_RATIO]
                       [--hybrid-override-pattern HYBRID_OVERRIDE_PATTERN]
                       [--yaml-cfg YAML_CFG] [--no-one-logger]
                       [--one-logger-project ONE_LOGGER_PROJECT]
                       [--one-logger-run-name ONE_LOGGER_RUN_NAME]
                       [--one-logger-async]
                       [--app-tag-run-name APP_TAG_RUN_NAME]
                       [--app-tag-run-version APP_TAG_RUN_VERSION]
                       [--use-fused-rmsnorm] [--use-fused-swiglu]
                       [--use-fused-rotary-pos-emb]
                       [--use-fused-ring-attention-update] [--use-mc2]
                       [--use-fused-mlp]
                       [--padded-vocab-size PADDED_VOCAB_SIZE]
                       [--embed-layernorm] [--use-glm-rope]
                       [--sliding-window SLIDING_WINDOW]
                       [--output-layer-slice-num OUTPUT_LAYER_SLICE_NUM]
                       [--lora-target-modules LORA_TARGET_MODULES [LORA_TARGET_MODULES ...]]
                       [--lora-load LORA_LOAD] [--lora-r LORA_R]
                       [--lora-alpha LORA_ALPHA]
                       [--lora-modules-to-save LORA_MODULES_TO_SAVE [LORA_MODULES_TO_SAVE ...]]
                       [--lora-register-forward-hook LORA_REGISTER_FORWARD_HOOK [LORA_REGISTER_FORWARD_HOOK ...]]
                       [--lora-fusion] [--lora-ckpt-filter] [--qlora]
                       [--qlora-save-dequantize] [--is-instruction-dataset]
                       [--full-shuffle-instruction-dataset]
                       [--variable-seq-lengths]
                       [--tokenizer-kwargs TOKENIZER_KWARGS [TOKENIZER_KWARGS ...]]
                       [--tokenizer-padding-side TOKENIZER_PADDING_SIDE]
                       [--tokenizer-type {BertWordPieceLowerCase,BertWordPieceCase,GPT2BPETokenizer,SentencePieceTokenizer,GPTSentencePieceTokenizer,Llama2Tokenizer,PretrainedFromHF,NullTokenizer}]
                       [--tokenizer-name-or-path TOKENIZER_NAME_OR_PATH]
                       [--tokenizer-not-use-fast] [--input-layernorm-in-fp32]
                       [--no-shuffle] [--neat-pack] [--padded-samples]
                       [--expert-interval EXPERT_INTERVAL]
                       [--moe-train-capacity-factor MOE_TRAIN_CAPACITY_FACTOR]
                       [--use-fused-moe-token-permute-and-unpermute]
                       [--gemm-gradient-accumulation-fusion]
                       [--moe-token-dispatcher-type {allgather,alltoall}]
                       [--noisy-gate-policy NOISY_GATE_POLICY]
                       [--enable-token-rearrange-opt]
                       [--embedding-multiplier-scale EMBEDDING_MULTIPLIER_SCALE]
                       [--input-jitter] [--post-norm]
                       [--output-multiplier-scale OUTPUT_MULTIPLIER_SCALE]
                       [--moe-permutation-async-comm] [--shared-expert-gate]
                       [--shared-expert-gate-output-dimension SHARED_EXPERT_GATE_OUTPUT_DIMENSION]
                       [--moe-alltoall-overlap-comm]
                       [--cla-share-factor CLA_SHARE_FACTOR]
                       [--moe-tp-extend-ep]
                       [--moe-zero-memory {disable,level0,level1}]
                       [--moe-zero-memory-num-layers MOE_ZERO_MEMORY_NUM_LAYERS]
                       [--moe-allgather-overlap-comm]
                       [--num-layer-list NUM_LAYER_LIST]
                       [--profile-ranks PROFILE_RANKS [PROFILE_RANKS ...]]
                       [--profile-export-type {text,db}]
                       [--profile-level {level_none,level0,level1,level2}]
                       [--profile-data-simplification] [--profile-with-stack]
                       [--profile-with-memory] [--profile-record-shapes]
                       [--profile-with-cpu]
                       [--profile-save-path PROFILE_SAVE_PATH]
                       [--add-qkv-bias] [--add-dense-bias]
                       [--add-output-layer-bias] [--skip-bias-add]
                       [--add-rmsnorm-offset] [--geglu] [--input-embeds-norm]
                       [--gelu-tanh]
                       [--output-logit-softcapping OUTPUT_LOGIT_SOFTCAPPING]
                       [--attn-logit-softcapping ATTN_LOGIT_SOFTCAPPING]
                       [--query-pre-attn-scalar QUERY_PRE_ATTN_SCALAR]
                       [--interleave-sliding-window INTERLEAVE_SLIDING_WINDOW]
                       [--stage {sft,dpo,orm,prm,simpo,ray_ppo,ray_online_dpo,ray_grpo,trl_ppo}]
                       [--cut-max-seqlen]
                       [--transformer-impl {local,transformer_engine}]
                       [--enable-recompute-layers-per-pp-rank]
                       [--pre-tockens PRE_TOCKENS]
                       [--next-tockens NEXT_TOCKENS]
                       [--sparse-mode SPARSE_MODE]
                       [--shape-order {SBH,BSH,BSND,BNSD}] [--use-deter-comp]
                       [--jit-compile]
                       [--prompt-type {default,empty,trl,chatglm2,chatglm3,chatglm3_system,glm4,chatml,chatml_de,qwen,qwen_r1,qwen_math_r1,llama3,llama2,mistral,mixtral,gemma,alpaca,deepseek2,deepseek2-lite,minicpm3,cpm,baichuan2,deepseek3,intern2,hunyuan,qwen3}]
                       [--prompt-type-path PROMPT_TYPE_PATH]
                       [--pad-to-multiple-of PAD_TO_MULTIPLE_OF]
                       [--scale-emb SCALE_EMB]
                       [--dim-model-base DIM_MODEL_BASE] [--no-cut-token]
                       [--scale-depth SCALE_DEPTH] [--swap-attention]
                       [--swap-modules SWAP_MODULES]
                       [--load-checkpoint-loosely] [--no-post-layer-norm]
                       [--return-document-ids] [--reset-attention-mask]
                       [--swap-optimizer]
                       [--swap-optimizer-times SWAP_OPTIMIZER_TIMES]
                       [--local-rank LOCAL_RANK]
                       [--distributed-timeout-minutes DISTRIBUTED_TIMEOUT_MINUTES]
                       [--noop-layers NOOP_LAYERS] [--reuse-fp32-param]
                       [--recompute-activation-function]
                       [--recompute-activation-function-num-layers RECOMPUTE_ACTIVATION_FUNCTION_NUM_LAYERS]
                       [--recompute-in-advance] [--recompute-norm]
                       [--recompute-norm-num-layers RECOMPUTE_NORM_NUM_LAYERS]
                       [--o2-optimizer] [--o2-gradient] [--share-kvstates]
                       [--square-alibi-mask] [--fill-neg-inf]
                       [--no-shared-storage]
                       [--dataset-additional-keys [DATASET_ADDITIONAL_KEYS ...]]
                       [--context-parallel-algo {ulysses_cp_algo,megatron_cp_algo,hybrid_cp_algo,adaptive_cp_algo,hybrid_adaptive_cp_algo}]
                       [--ulysses-degree-in-cp ULYSSES_DEGREE_IN_CP]
                       [--attention-mask-type {causal,general}]
                       [--cp-attention-mask-type {causal,general}]
                       [--use-cp-send-recv-overlap]
                       [--cp-window-size CP_WINDOW_SIZE]
                       [--attention-mask-on-cpu]
                       [--adaptive-cp-without-coarse]
                       [--adaptive-cp-dynamic-attn-mask]
                       [--adaptive-cp-only-reschedule]
                       [--adaptive-cp-manually-set-mask-list]
                       [--kv-head-repeat-before-uly-alltoall]
                       [--multi-head-latent-attention]
                       [--padded-base-length PADDED_BASE_LENGTH]
                       [--q-lora-rank Q_LORA_RANK]
                       [--kv-lora-rank KV_LORA_RANK] [--v-head-dim V_HEAD_DIM]
                       [--qk-rope-head-dim QK_ROPE_HEAD_DIM]
                       [--qk-nope-head-dim QK_NOPE_HEAD_DIM]
                       [--mla-fa-without-pad] [--mla-mm-split]
                       [--mla-zero-memory] [--mla-up-proj-tp-overlap]
                       [--recompute-mla-up-proj] [--mla-swap-core-attn-out]
                       [--mla-fa-divide-qk]
                       [--rope-scaling-beta-fast ROPE_SCALING_BETA_FAST]
                       [--rope-scaling-beta-slow ROPE_SCALING_BETA_SLOW]
                       [--rope-scaling-factor ROPE_SCALING_FACTOR]
                       [--rope-scaling-mscale ROPE_SCALING_MSCALE]
                       [--rope-scaling-mscale-all-dim ROPE_SCALING_MSCALE_ALL_DIM]
                       [--rope-scaling-original-max-position-embeddings ROPE_SCALING_ORIGINAL_MAX_POSITION_EMBEDDINGS]
                       [--moe-intermediate-size MOE_INTERMEDIATE_SIZE]
                       [--n-shared-experts N_SHARED_EXPERTS]
                       [--first-k-dense-replace FIRST_K_DENSE_REPLACE]
                       [--moe-layer-freq MOE_LAYER_FREQ]
                       [--mtp-num-layers MTP_NUM_LAYERS]
                       [--mtp-loss-scaling-factor MTP_LOSS_SCALING_FACTOR]
                       [--recompute-mtp-norm] [--recompute-mtp-layer]
                       [--mtp-mem-efficient-logits] [--dpo-beta DPO_BETA]
                       [--simpo-beta SIMPO_BETA]
                       [--gamma-beta-ratio GAMMA_BETA_RATIO]
                       [--dpo-loss-type {sigmoid,hinge,ipo}]
                       [--simpo-loss-type {sigmoid,hinge,ipo}]
                       [--simpo-label-smoothing SIMPO_LABEL_SMOOTHING]
                       [--ref-model REF_MODEL]
                       [--refer-model-iter REFER_MODEL_ITER]
                       [--dpo-label-smoothing DPO_LABEL_SMOOTHING]
                       [--pref-ftx PREF_FTX] [--is-pairwise-dataset]
                       [--placeholder-token PLACEHOLDER_TOKEN]
                       [--md5-validate]
                       [--max-prompt-length MAX_PROMPT_LENGTH]
                       [--num-samples-per-step NUM_SAMPLES_PER_STEP]
                       [--rollout-batch-size ROLLOUT_BATCH_SIZE]
                       [--cliprange-value CLIPRANGE_VALUE]
                       [--critic-mini-batch-size CRITIC_MINI_BATCH_SIZE]
                       [--critic-update-epochs CRITIC_UPDATE_EPOCHS]
                       [--ppo-mini-batch-size PPO_MINI_BATCH_SIZE]
                       [--clip-ratio CLIP_RATIO]
                       [--entropy-coeff ENTROPY_COEFF]
                       [--ppo-epochs PPO_EPOCHS] [--shuffle-minibatch]
                       [--do-sample]
                       [--missing-eos-penalty MISSING_EOS_PENALTY]
                       [--n-samples-per-prompt N_SAMPLES_PER_PROMPT]
                       [--reward-tokens REWARD_TOKENS [REWARD_TOKENS ...]]
                       [--reward-model REWARD_MODEL] [--verifier]
                       [--kl-coef KL_COEF] [--gamma GAMMA] [--lam LAM]
                       [--advantage-whiten ADVANTAGE_WHITEN]
                       [--dataset-category DATASET_CATEGORY]
                       [--extract-content-for-reward EXTRACT_CONTENT_FOR_REWARD]
                       [--use-nd-matmul] [--nd1-dim1-size ND1_DIM1_SIZE]
                       [--nd2-dim1-size ND2_DIM1_SIZE] [--tp-2d] [--tp-x TP_X]
                       [--tp-y TP_Y] [--enable-overlap-ag-with-matmul]
                       [--enable-overlap-matmul-with-rs]
                       [--enable-backward-overlap-ag-with-matmul]
                       [--hccl-group-buffer HCCL_GROUP_BUFFER]
                       [--use-mcore-models]
                       [--num-gpus-for-train NUM_GPUS_FOR_TRAIN]
                       [--num-gpus-for-infer NUM_GPUS_FOR_INFER]
                       [--inference-tensor-model-parallel-size INFERENCE_TENSOR_MODEL_PARALLEL_SIZE]
                       [--task [TASK ...]] [--top-p TOP_P] [--top-k TOP_K]
                       [--temperature TEMPERATURE] [--max-length MAX_LENGTH]
                       [--max-new-tokens MAX_NEW_TOKENS] [--hf-chat-template]
                       [--add-eos-token ADD_EOS_TOKEN [ADD_EOS_TOKEN ...]]
                       [--use-kv-cache] [--history-turns HISTORY_TURNS]
                       [--moe-fb-overlap] [--schedules-method {dualpipev}]
                       [--dualpipev-dw-detach] [--moe-unperm2-mem-optim]
                       [--moe-unperm2-mem-optim-swap]
                       [--ai-framework {pytorch,mindspore}]
                       [--async-log-allreduce] [--moe-zerc]
                       [--unaligned-linear] [--enable-share-memory]
                       [--disable-gloo-group]
                       [--hccl-slice-size HCCL_SLICE_SIZE]
                       [--rope-scaling-type {llama3,yarn,longrope}]
                       [--original-max-position-embeddings ORIGINAL_MAX_POSITION_EMBEDDINGS]
                       [--longrope-freqs-type {mul,outer}]
                       [--low-freq-factor LOW_FREQ_FACTOR]
                       [--high-freq-factor HIGH_FREQ_FACTOR]
                       [--long-factor LONG_FACTOR]
                       [--short-factor SHORT_FACTOR]
                       [--long-mscale LONG_MSCALE]
                       [--short-mscale SHORT_MSCALE]
                       [--dynamic-factor DYNAMIC_FACTOR]
                       [--mamba-ngroups MAMBA_NGROUPS]
                       [--mamba-d-ssm MAMBA_D_SSM]
                       [--mamba-chunk-size MAMBA_CHUNK_SIZE]
                       [--mamba-d-state MAMBA_D_STATE]
                       [--mamba-d-conv MAMBA_D_CONV]
                       [--mamba-expand MAMBA_EXPAND]
                       [--mamba-headdim MAMBA_HEADDIM]
                       [--moe-router-load-balancing-type {aux_loss,group_limited_greedy,softmax_topk,pai_megatron_aux_loss,sparsemixer_topk,noaux_tc,none}]
                       [--moe-z-loss-coeff MOE_Z_LOSS_COEFF]
                       [--moe-expert-capacity-factor MOE_EXPERT_CAPACITY_FACTOR]
                       [--topk-group TOPK_GROUP]
                       [--routed-scaling-factor ROUTED_SCALING_FACTOR]
                       [--norm-topk-prob]
                       [--moe-router-score-function {softmax,sigmoid}]
                       [--moe-router-enable-expert-bias] [--n-group N_GROUP]
                       [--seq-aux]
                       [--moe-device-level-aux-loss-coeff MOE_DEVICE_LEVEL_AUX_LOSS_COEFF]
                       [--moe-comm-aux-loss-coeff MOE_COMM_AUX_LOSS_COEFF]
                       [--router-gating-in-fp32]
                       [--moe-router-bias-update-rate MOE_ROUTER_BIAS_UPDATE_RATE]
                       [--moe-revert-type-after-topk] [--fix-router]
                       [--use-ascend-coc] [--coc-mode COC_MODE]
                       [--coc-parallel-num COC_PARALLEL_NUM]
                       [--coc-fused-kernel] [--enable-high-availability]
                       [--enable-optimizer-state-local-copy]
                       [--enable-hbmfault-repair]
pretrain_gpt.py: error: unrecognized arguments: --log_timers_to_tensorboard true
